{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyjTk6aV4lfRAYupFbWmRg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhruvin3103/sem6/blob/master/ml/emp_left_log_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "yYQqWkr1Wg-m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/codebasics/py/master/ML/7_logistic_reg/Exercise/HR_comma_sep.csv\")\n",
        "df.tail(5)\n",
        "df['left'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6zT5YdaWjhr",
        "outputId": "ba1a8878-0d66-4823-90c2-9c5cdc208adc"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    11428\n",
              "1     3571\n",
              "Name: left, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['number_project','time_spend_company']]\n",
        "y =df[\"left\"].values\n",
        "X = X.values\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArhSXtRJXMg7",
        "outputId": "3a5c8552-ac4d-45a4-d4b1-483890553afd"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 3],\n",
              "       [5, 6],\n",
              "       [7, 4],\n",
              "       ...,\n",
              "       [2, 3],\n",
              "       [6, 4],\n",
              "       [2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is cell carries out the code to reduce dataset so that number of records for both class 0 and 1 are equal\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X and Y are your input features and labels\n",
        "# Replace X and Y with your actual dataset\n",
        "\n",
        "# Find the indices of records for each class\n",
        "indices_class_0 = np.where(y == 0)[0]\n",
        "indices_class_1 = np.where(y == 1)[0]\n",
        "\n",
        "# Determine the number of records to keep for each class (equal to the size of the minority class)\n",
        "num_records_to_keep = min(len(indices_class_0), len(indices_class_1))\n",
        "\n",
        "# Randomly sample a subset of records for each class\n",
        "selected_indices_class_0 = np.random.choice(indices_class_0, size=num_records_to_keep, replace=False)\n",
        "selected_indices_class_1 = np.random.choice(indices_class_1, size=num_records_to_keep, replace=False)\n",
        "\n",
        "# Combine the selected indices for both classes\n",
        "selected_indices = np.concatenate([selected_indices_class_0, selected_indices_class_1])\n",
        "\n",
        "# Extract the subset of the dataset based on the selected indices\n",
        "X = X[selected_indices]\n",
        "y = y[selected_indices]\n",
        "\n",
        "# y.value_counts()"
      ],
      "metadata": {
        "id": "LPHhKmm2hoIf"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y,train_size=0.7,random_state=42)\n",
        "Y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaanVu6GXGs3",
        "outputId": "205e5722-685a-4d18-d21a-2e25a450630b"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def initialize_params(dim):\n",
        "    return np.zeros((dim, 1)), 0\n",
        "\n",
        "def propagate(X, Y, w, b):\n",
        "    m = X.shape[1]\n",
        "\n",
        "    # Forward propagation\n",
        "    A = sigmoid(np.dot(w.T, X) + b)\n",
        "    epsilon = 1e-15  # Small epsilon value to avoid log(0)\n",
        "    cost = -1/m * np.sum(Y * np.log(A + epsilon) + (1 - Y) * np.log(1 - A + epsilon))\n",
        "\n",
        "    # Backward propagation\n",
        "    dw = 1/m * np.dot(X, (A - Y).T)\n",
        "    db = 1/m * np.sum(A - Y)\n",
        "\n",
        "    return dw, db, cost\n",
        "\n",
        "def optimize(X, Y, w, b, num_iterations, learning_rate):\n",
        "    costs = []\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        dw, db, cost = propagate(X, Y, w, b)\n",
        "\n",
        "        # Gradient descent\n",
        "        w -= learning_rate * dw\n",
        "        b -= learning_rate * db\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            costs.append(cost)\n",
        "\n",
        "    return w, b, costs\n",
        "\n",
        "def predict(X, w, b):\n",
        "    A = sigmoid(np.dot(w.T, X) + b)\n",
        "    return (A > 0.5).astype(int)\n",
        "\n",
        "def accuracy(Y_true, Y_pred):\n",
        "    return np.mean(Y_true == Y_pred)\n",
        "\n",
        "def confusion_matrix(Y_true, Y_pred):\n",
        "    tp = np.sum((Y_true == 1) & (Y_pred == 1))\n",
        "    tn = np.sum((Y_true == 0) & (Y_pred == 0))\n",
        "    fp = np.sum((Y_true == 0) & (Y_pred == 1))\n",
        "    fn = np.sum((Y_true == 1) & (Y_pred == 0))\n",
        "\n",
        "    return np.array([[tp, fp], [fn, tn]])\n",
        "\n",
        "# Assuming X_train, Y_train, X_test, Y_test are your training and testing sets\n",
        "X_train = X_train.T\n",
        "Y_train = Y_train.reshape(1, -1)\n",
        "\n",
        "X_test = X_test.T\n",
        "Y_test = Y_test.reshape(1, -1)\n",
        "\n",
        "# Initialize parameters\n",
        "w, b = initialize_params(X_train.shape[0])\n",
        "\n",
        "# Optimize the parameters using gradient descent\n",
        "w, b, costs = optimize(X_train, Y_train, w, b, num_iterations=5000, learning_rate=0.01)\n",
        "\n",
        "Y_test_pred = predict(X_test, w, b)\n",
        "\n",
        "acc_test = accuracy(Y_test.flatten(), Y_test_pred.flatten())\n",
        "conf_mat_test = confusion_matrix(Y_test.flatten(), Y_test_pred.flatten())\n",
        "\n",
        "print(\"\\nTesting Accuracy:\", acc_test)\n",
        "print(\"Testing Confusion Matrix:\")\n",
        "print(conf_mat_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtER_l2pcF2_",
        "outputId": "e3289e7c-dfe0-4de0-8ad3-3ff96a57986d"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Accuracy: 0.7162855809612693\n",
            "Testing Confusion Matrix:\n",
            "[[799 366]\n",
            " [242 736]]\n"
          ]
        }
      ]
    }
  ]
}